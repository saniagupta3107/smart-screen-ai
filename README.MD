# ResumeÂ ScreeningÂ & EmployeeÂ SentimentÂ Analysis

A twoâ€‘part ML project that

1. ranks rÃ©sumÃ©s against a job description, and
2. predicts employeeâ€‘attrition risk from freeâ€‘text feedback and recommends an engagement strategy via a Flask API.

---

## ğŸ“‚Â Project Layout

```
.
â”œâ”€â”€ app.py                     #Â Flask API for TaskÂ 2
â”œâ”€â”€ train_model.py             #Â Modelâ€‘training script for TaskÂ 2
â”œâ”€â”€ notebooks/
â”‚Â Â  â”œâ”€â”€ preprocess.ipynb               #Â text cleaning helpers (rÃ©sumÃ©s)
â”‚Â Â  â”œâ”€â”€ resume_screening.ipynb         #Â TFâ€‘IDF rÃ©sumÃ© ranking demo
â”‚Â Â  â”œâ”€â”€ resume_screening2.ipynb        #Â EmbeddingsÂ +Â NER rÃ©sumÃ© ranking demo
â”‚Â Â  â”œâ”€â”€ preporcess_EmpData.ipynb       #Â data wrangling for employee dataset
â”‚Â Â  â””â”€â”€ EmployeeSentiment.ipynb        #Â model exploration + evaluation
â”œâ”€â”€ data/
â”‚Â Â  â”œâ”€â”€ resumes.csv
â”‚Â Â  â””â”€â”€ combined_employee_data.csv
â”œâ”€â”€ model/
â”‚Â Â  â”œâ”€â”€ model.pkl              #Â Randomâ€‘Forest attrition model
â”‚Â Â  â””â”€â”€ label_encoder.pkl      #Â Saved LabelEncoder
â””â”€â”€ requirements.txt
```

---

## 1Â Â ResumeÂ Screening (TaskÂ 1)

### 1.1Â Â Quickâ€‘Start

```bash
#Â Run the TFâ€‘IDF demo
jupyterÂ notebook notebooks/resume_screening.ipynb

#Â Run the EmbeddingÂ +Â NER demo
jupyterÂ notebook notebooks/resume_screening2.ipynb
```

### 1.2Â Â PipelinesÂ â©

| Step | TFâ€‘IDFÂ Approach                         | EmbeddingÂ +Â NER Approach                          |
| ---- | --------------------------------------- | ------------------------------------------------- |
| 1    | Load `resumes.csv`                      | Load `resumes.csv`                                |
| 2    | Add **jobÂ description** to corpus       | Add **jobÂ description** to corpus                 |
| 3    | `TfidfVectorizer(stop_words='english')` | Clean text âœ spaCy NER âœ extract skills           |
| 4    | Cosine similarity (`sklearn.metrics`)   | Embed with **BAAI/bgeâ€‘smallâ€‘enÂ v1.5** (LangChain) |
| 5    | Rank & sort by similarity               | Cosine similarity (`scipy`) & rank                |

> **Output:** `top_k` rÃ©sumÃ©s most relevant to the description.

---

## 2Â Â EmployeeÂ SentimentÂ API (TaskÂ 2)

An HTTP endpoint that returns attritionâ€‘risk predictions and engagement advice.

### 2.1Â Â Train the Model

```bash
python train_model.py          #Â creates model/model.pkl & model/label_encoder.pkl
```

Pipeline (condensed):
1.Â Load `combined_employee_data.csv`.
2.Â Extract `cessation_year` (regex).
3.Â Compute `sentiment_score` (TextBlob polarity).
4.Â Label `attrition_risk` (keyword rule).
5.Â Trainâ€‘test split 60/40.
6.Â RandomForest on `cessation_year + sentiment_score`.
7.Â Persist artefacts with `joblib`.

### 2.2Â Â Run Locally

```bash
pip install -r requirements.txt
python -m textblob.download_corpora   #Â oneâ€‘time for sentiment

# Dev server
python app.py                         #Â listens on :5000

# Prod
gunicorn app:app -b 0.0.0.0:8000 -w 4
```

### 2.3Â Â API Reference

| Method | Endpoint   | Body                                               | Description                       |
| ------ | ---------- | -------------------------------------------------- | --------------------------------- |
| POST   | `/predict` | `{"feedback":"The workload is very comfortableâ€¦"}` | Returns JSON with risk & strategy |

Sample Response

```json
{
  "feedback": "The workload is very comfortable and I often don't have to stay late.",
  "sentiment_score": 0.35,
  "model_probability": 0.11,
  "predicted_attrition_risk": false,
  "engagement_strategy": "Maintain current engagement and recognition programs."
}
```

A live deployment is available at **[https://employee-feedback-ww3a.onrender.com/predict](https://employee-feedback-ww3a.onrender.com/predict)**.

---

## ğŸ› ï¸Â Installation

```bash
python -m venv venv && source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

> If using the rÃ©sumÃ©â€‘ranking notebooks, you may also need to download spaCy & HF assets:
>
> ```bash
> python -m spacy download en_core_web_sm
> ```

---

## ğŸš€Â Deployment on Render

1. **Preâ€‘Deploy Command**: `python -m textblob.download_corpora`
2. **Start Command**: `gunicorn app:app`
   (Configure these in the Render dashboard or `render.yaml`.)

---

## âœï¸Â Author & License

Created by **Dilshad**. Licensed under the MIT License.
